{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sdi1700152.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k6lh-MW8j3_"
      },
      "source": [
        "# ***Readme***\n",
        "\n",
        "ΣΤΙΒΑΚΤΑΣ ΕΜΜΑΝΟΥΗΛ\n",
        "Α.Μ = 1115201700152\n",
        "\n",
        "\n",
        "Έχουν υλοποιηθεί όλα τα ερωτήματα της εργασίας . Μερικές παρατηρήσεις:\n",
        "\n",
        "\n",
        "1) Έχει χρησιμοποιηθεί κώδικας απο την προηγούμενη εργασία όπως η συνάρτηση find_classification(). Όπου χρησιμοποιήθηκαν πηγές από το διαδίκτυο αναγράφονται στα σχόλια.\n",
        "\n",
        "\n",
        "2) Διαβάζω τα train και test δεδομενα. Έπειτα από το κατάλληλο text cleaning εκπαιδέυω τα δεδομένα με τους αλγορίθμους ταξινόμησης .\n",
        "\n",
        "\n",
        "3) Για το count vectorizer τα καλύτερα ποσοστά βγήκαν στον naive bayes όταν χρησιμοποιήθηκε laplace smoothing.  Bigrams και lemmatization αύξησαν εξίσου τα ποσοστά, όχι όμως όπως με τον laplace. Να τονιστεί πως με την αφαίρεση των stopwords  παρατηρήθηκε ελάχιστη μείωση στα ποσοστά. Αυτό το φαινόμενο μπορεί να εξηγηθεί, καθώς σε μερικές περιπτώσεις η μείωση/τροποποίηση των λέξεων μπορεί να οδηγήσει στην αλλαγή νοήματος των προτάσεων και να υπάρξουν παρερμηνείες. Επίσης , υπάρχουν αναλυτικά όλα τα ποσοστά τόσο για τα train data όσο και για τα test data για όλους τους αλγορίθμους. \n",
        "\n",
        "\n",
        "4) Για τον σύνθετο πίνακα tfidf-pos τα καλύτερα ποσοστά παρατηρήθηκαν με τον svm. Τελικά κάνοντας το κατάλληλο parameter tunning τα ποσοστά στον svm και στον random forrest αυξήθηκαν σημαντικά. Χαρακτηριστικά το  accuracy του svc πήγε απο 66.93% σε 71.81% και για τον random forest από 62.68% σε 67.64%. \n",
        "\n",
        "\n",
        "5) Παρόλα αυτά , το καλύτερο ποσοστό από όλους τους αλγορίθμους ταξινόμησης για το test data ήταν με τον SGDClassifier για τον σύνθετο πίνακα στο 72.25%.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaJfDnRrw9GJ"
      },
      "source": [
        "# Headers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwAbLMT68j4E"
      },
      "source": [
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "import numpy as np\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import re\n",
        "import string\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we3XAMs6I1C7"
      },
      "source": [
        "# Reading files "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ptb5IMZP8j4X"
      },
      "source": [
        "train_set = pd.read_csv('data/train.csv')\n",
        "test_set = pd.read_csv('data/impermium_verification_set.csv')\n",
        "test_set_evaluation = pd.read_csv('data/impermium_verification_labels.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU1v0dlP8j4t"
      },
      "source": [
        "#  Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eydCkzMdGGWf"
      },
      "source": [
        "# dictionary inspired by https://stackoverflow.com/questions/43018030/replace-apostrophe-short-words-in-python\n",
        "# Making words with apostrophes into mutiple words \n",
        "# More friendly for computer to understand the meaning of the phrase\n",
        "\n",
        "contractions = {\n",
        "\"ain't\": \"am not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he'll've\": \"he will have\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"i'd\": \"I would\",\n",
        "\"i'd've\": \"I would have\",\n",
        "\"i'll\": \"I will\",\n",
        "\"i'll've\": \"I will have\",\n",
        "\"i'm\": \"I am\",\n",
        "\"i've\": \"I have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it'll've\": \"it will have\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \" she will\",\n",
        "\"she'll've\": \"she will have\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so is\",\n",
        "\"that'd\": \"that would\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they'll've\": \"they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what'll've\": \"what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\":  \"when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who'll've\": \"who will have\",\n",
        "\"who's\": \"who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you'll've\": \"you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}\n",
        "\n",
        "punctuation = '\"'\n",
        "\n",
        "row = 0\n",
        "for comment in train_set.Comment:\n",
        "    comment = comment.translate(str.maketrans('', '', punctuation))\n",
        "    for word in comment.split():\n",
        "        if word.lower() in contractions:\n",
        "            comment = comment.replace(word, contractions[word.lower()])  \n",
        "    train_set.loc[row, 'Comment'] = comment\n",
        "    row += 1\n",
        "\n",
        "row = 0\n",
        "for comment in test_set.Comment:\n",
        "    comment = comment.translate(str.maketrans('', '', punctuation)) \n",
        "    for word in comment.split():\n",
        "        if word.lower() in contractions:\n",
        "            comment = comment.replace(word, contractions[word.lower()]) \n",
        "    test_set.loc[row, 'Comment'] = comment\n",
        "    row += 1        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkEikSu68j4w"
      },
      "source": [
        "# List with indexes of rows of train_set we want to drop\n",
        "rows_to_be_deleted_train = [] \n",
        "rows_to_be_deleted_test = [] \n",
        "\n",
        "# Lowercase\n",
        "train_set.Comment = train_set.Comment.apply(lambda x: x.lower())\n",
        "test_set.Comment = test_set.Comment.apply(lambda x: x.lower())\n",
        "\n",
        "# Remove url\n",
        "train_set.Comment = train_set.Comment.apply(lambda x: re.sub(r'http\\S+', ' ', x))\n",
        "test_set.Comment = test_set.Comment.apply(lambda x: re.sub(r'http\\S+', ' ', x))\n",
        "\n",
        "\n",
        "# Help us to seperate '\\' from words \n",
        "train_set.Comment = train_set.Comment.apply(lambda x: x.replace('\\\\', ' \\\\'))\n",
        "test_set.Comment = test_set.Comment.apply(lambda x: x.replace('\\\\', ' \\\\'))\n",
        "\n",
        "# Remove '\\xa0'\n",
        "train_set.Comment = train_set.Comment.apply(lambda x: re.sub(r'\\\\xa0', ' ', x))\n",
        "test_set.Comment = test_set.Comment.apply(lambda x: re.sub(r'\\\\xa0', ' ', x))\n",
        "\n",
        "# Remove '\\n'\n",
        "train_set.Comment = train_set.Comment.apply(lambda x: re.sub(r'\\\\n', ' ', x))\n",
        "test_set.Comment = test_set.Comment.apply(lambda x: re.sub(r'\\\\n', ' ', x))\n",
        "\n",
        "# Remove '\\u'\n",
        "train_set.Comment = train_set.Comment.apply(lambda x: re.sub(r'\\\\u', ' ', x))\n",
        "test_set.Comment = test_set.Comment.apply(lambda x: re.sub(r'\\\\u', ' ', x))\n",
        "\n",
        "# Remove numbers\n",
        "train_set.Comment = train_set.Comment.apply(lambda x:re.sub(\"\\d+\", \" \", x))\n",
        "train_set.Comment = train_set.Comment.apply(lambda x:re.sub(\"\\d+\", \" \", x))\n",
        "\n",
        "# Remove words that have '\\'\n",
        "train_set.Comment = train_set.Comment.apply(lambda x: re.sub(r'\\\\[a-z]*', ' ', x))\n",
        "test_set.Comment = test_set.Comment.apply(lambda x: re.sub(r'\\\\[a-z]*', ' ', x))\n",
        "\n",
        "\n",
        "# Remove punctuation\n",
        "train_set.Comment = train_set.Comment.apply(lambda x: x.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))))\n",
        "test_set.Comment = test_set.Comment.apply(lambda x: x.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))))\n",
        "\n",
        "# Delete multiple consecutive spaces\n",
        "train_set.Comment = train_set.Comment.apply(lambda x: ' '.join(x.split()))\n",
        "test_set.Comment = test_set.Comment.apply(lambda x: ' '.join(x.split()))\n",
        "\n",
        "# After text cleaning drop rows for test and train data that have \"invalid\" comment \n",
        "\n",
        "row = 0\n",
        "for comment in train_set.Comment:\n",
        "    if ((comment == \"\")==True or (comment == \" \")==True): \n",
        "        rows_to_be_deleted_train.append(row)  \n",
        "    row = row + 1\n",
        "\n",
        "row = 0\n",
        "for comment in test_set.Comment:\n",
        "    if ((comment == \"\")==True or (comment == \" \")==True): \n",
        "        rows_to_be_deleted_test.append(row)  \n",
        "    row = row + 1    \n",
        "\n",
        "train_set.drop(train_set.index[rows_to_be_deleted_train], inplace=True)  \n",
        "test_set.drop(test_set.index[rows_to_be_deleted_test], inplace=True) \n",
        "test_set_evaluation.drop(test_set_evaluation.index[rows_to_be_deleted_test], inplace=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8L9_wSI8j5K"
      },
      "source": [
        "stopwords = list(STOPWORDS) \n",
        "\n",
        "# Creating bag of words for train and test set\n",
        "bow_vectorizer = CountVectorizer()\n",
        "bow_train = bow_vectorizer.fit_transform(train_set[\"Comment\"])\n",
        "bow_test =  bow_vectorizer.transform(test_set[\"Comment\"])\n",
        "\n",
        "# Actual insults of train data\n",
        "train_y = train_set[\"Insult\"].to_numpy()\n",
        "train_y = train_y.astype('int')\n",
        "\n",
        "# Actual test_set insults values\n",
        "actual_test_set_y = test_set_evaluation[\"Insult\"].to_numpy()\n",
        "actual_test_set_y = actual_test_set_y.astype('int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNvYm9wz8j5W"
      },
      "source": [
        "# Trains data with model and evaluates classification \n",
        "\n",
        "def Find_Classification(model , my_array , train_y , my_model):\n",
        "\n",
        "    #lists for k fold cross val\n",
        "    list_accuracy=[]\n",
        "    list_f1=[]\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=3)\n",
        "\n",
        "    #kf.split gives us 10 different splits \n",
        "    for train_index, test_index in kf.split(bow_train.toarray() , train_y):\n",
        "        X_train, X_test = my_array[train_index], my_array[test_index]\n",
        "        y_train, y_test = train_y[train_index], train_y[test_index]\n",
        "        \n",
        "        #fit and predict\n",
        "        model.fit(X_train,y_train)\n",
        "        y_pred= model.predict(X_test)\n",
        "        \n",
        "        #Save metrics to calculate average scores\n",
        "        list_accuracy.append(100* metrics.accuracy_score(y_test,y_pred) )\n",
        "        list_f1.append(100 *f1_score(y_test,y_pred) )\n",
        "\n",
        "        \n",
        "    print(my_model, \"Accuracy metric\", sum(list_accuracy) /len(list_accuracy))\n",
        "    print(my_model, \"F1 metric\",sum(list_f1) /len(list_f1))\n",
        "    print(\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QlBop0e8j5h"
      },
      "source": [
        "# Improving scores on train set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENX06u9h8j5j"
      },
      "source": [
        "## 1) Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaCG7wcp8j5l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "fe515c19-b95c-4e8c-e329-873de5d071ee"
      },
      "source": [
        "train_set_comment_lem = train_set.Comment\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "train_set_comment_lem = train_set_comment_lem.apply(lambda x: ' '.join([lemmatizer.lemmatize(w) for w in x.rstrip().split()]))\n",
        "bow_train_with_lem = bow_vectorizer.fit_transform(train_set_comment_lem)\n",
        "\n",
        "Find_Classification(GaussianNB(),  bow_train.toarray() , train_y, \"NaiveBayes BOW\")\n",
        "Find_Classification(GaussianNB(),  bow_train_with_lem.toarray() , train_y, \"NaiveBayes BOW with lemmatization\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "NaiveBayes BOW Accuracy metric 66.69215446893273\n",
            "NaiveBayes BOW F1 metric 44.46627366590176\n",
            "\n",
            "\n",
            "NaiveBayes BOW with lemmatization Accuracy metric 65.93201824840969\n",
            "NaiveBayes BOW with lemmatization F1 metric 44.89016439185612\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCFFtyBR8j5u"
      },
      "source": [
        "## 2) Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUISLiZm8j5v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "af06f974-31e7-4dae-eefc-692255b4cf40"
      },
      "source": [
        "bow_vectorizer_with_stopwords = CountVectorizer(stop_words=stopwords)\n",
        "bow_train_with_stopwords = bow_vectorizer_with_stopwords.fit_transform(train_set[\"Comment\"])\n",
        "Find_Classification(GaussianNB(),  bow_train.toarray() , train_y, \"NaiveBayes BOW\")\n",
        "Find_Classification(GaussianNB(),  bow_train_with_stopwords.toarray() , train_y, \"NaiveBayes BOW with stopwords\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NaiveBayes BOW Accuracy metric 66.69215446893273\n",
            "NaiveBayes BOW F1 metric 44.46627366590176\n",
            "\n",
            "\n",
            "NaiveBayes BOW with stopwords Accuracy metric 66.69221872389643\n",
            "NaiveBayes BOW with stopwords F1 metric 44.55750026458257\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2sPpEbh8j55"
      },
      "source": [
        "## 3) Bigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmQuvMEP8j58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "e2d69451-e6a0-4f79-e54f-07d71dc1f449"
      },
      "source": [
        "bow_vectorizer_with_bigrams = CountVectorizer(ngram_range=(2,2))\n",
        "bow_train_with_bigrams = bow_vectorizer_with_bigrams.fit_transform(train_set[\"Comment\"])\n",
        "Find_Classification(GaussianNB(),  bow_train.toarray() , train_y, \"NaiveBayes BOW\")\n",
        "Find_Classification(GaussianNB(),  bow_train_with_bigrams.toarray() , train_y, \"NaiveBayes BOW with bigrams\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NaiveBayes BOW Accuracy metric 66.69215446893273\n",
            "NaiveBayes BOW F1 metric 44.46627366590176\n",
            "\n",
            "\n",
            "NaiveBayes BOW with bigrams Accuracy metric 68.94988112831717\n",
            "NaiveBayes BOW with bigrams F1 metric 44.20455153394136\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i09uXHX8j6F"
      },
      "source": [
        "## 4) Laplace Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2hEXeFm8j6H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "8af0428e-c654-45c4-900a-4fafe55477f3"
      },
      "source": [
        "Find_Classification(GaussianNB(),  bow_train.toarray() , train_y, \"NaiveBayes BOW\")\n",
        "Find_Classification(MultinomialNB(alpha=1.0),  bow_train.toarray() , train_y, \"Multinomial NaiveBayes BOW\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NaiveBayes BOW Accuracy metric 66.69215446893273\n",
            "NaiveBayes BOW F1 metric 44.46627366590176\n",
            "\n",
            "\n",
            "Multinomial NaiveBayes BOW Accuracy metric 79.13840519180107\n",
            "Multinomial NaiveBayes BOW F1 metric 63.383834060714136\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5Zk3yYkKDuV"
      },
      "source": [
        "# Initial accuracy of NB model on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmpcy8r3TeZV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5bcb546d-69a0-4ffe-cddd-cd25245de990"
      },
      "source": [
        "model = GaussianNB()\n",
        "model.fit(bow_train.toarray(),train_y)\n",
        "y_pred = model.predict(bow_test.toarray())\n",
        "\n",
        "print( \"accuracy \",100 * metrics.accuracy_score(actual_test_set_y,y_pred))\n",
        "print( \"f1_Score \",100 * f1_score(actual_test_set_y,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy  51.856823266219244\n",
            "f1_Score  51.487826871055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1tr_fK6HZdV"
      },
      "source": [
        "# Evaluating improvements on test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9c2q_PYHpE5"
      },
      "source": [
        "## 1) Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yvlU0Q9HxLZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f2a966f0-693c-489a-af35-4aeeb292b17c"
      },
      "source": [
        "train_set_comment_lem = train_set.Comment\n",
        "test_set_comment_lem = test_set.Comment\n",
        "\n",
        "# nltk.download('wordnet')\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "train_set_comment_lem = train_set_comment_lem.apply(lambda x: ' '.join([lemmatizer.lemmatize(w) for w in x.rstrip().split()]))\n",
        "bow_train_with_lem = bow_vectorizer.fit_transform(train_set_comment_lem)\n",
        "\n",
        "test_set_comment_lem = test_set_comment_lem.apply(lambda x: ' '.join([lemmatizer.lemmatize(w) for w in x.rstrip().split()]))\n",
        "bow_test_with_lem = bow_vectorizer.transform(test_set_comment_lem)\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(bow_train_with_lem.toarray(),train_y)\n",
        "y_pred = model.predict(bow_test_with_lem.toarray())\n",
        "\n",
        "print( \"accuracy \",100 * metrics.accuracy_score(actual_test_set_y,y_pred))\n",
        "print( \"f1_Score \",100 * f1_score(actual_test_set_y,y_pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy  51.90156599552572\n",
            "f1_Score  52.32815964523281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1fT4_yuMgLd"
      },
      "source": [
        "## 2) Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t81ABJyMMfOf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "486bf718-68d2-40ae-9b4a-90838ea146f9"
      },
      "source": [
        "bow_vectorizer_with_stopwords = CountVectorizer(stop_words=stopwords)\n",
        "bow_train_with_stopwords = bow_vectorizer_with_stopwords.fit_transform(train_set[\"Comment\"])\n",
        "bow_test_with_stopwords = bow_vectorizer_with_stopwords.transform(test_set[\"Comment\"])\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(bow_train_with_stopwords.toarray(), train_y)\n",
        "y_pred = model.predict(bow_test_with_stopwords.toarray())\n",
        "\n",
        "print( \"accuracy \",100 * metrics.accuracy_score(actual_test_set_y,y_pred))\n",
        "print( \"f1_Score \",100 * f1_score(actual_test_set_y,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy  51.81208053691275\n",
            "f1_Score  51.464623704371334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm35gr_dQXox"
      },
      "source": [
        "## 3) Bigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvy-5HftQbqC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6c5eb57f-107a-49ea-a12c-890c524ecd96"
      },
      "source": [
        "bow_vectorizer_with_bigrams = CountVectorizer(ngram_range=(2,2))\n",
        "bow_train_with_bigrams = bow_vectorizer_with_bigrams.fit_transform(train_set[\"Comment\"])\n",
        "bow_test_with_bigrams = bow_vectorizer_with_bigrams.transform(test_set[\"Comment\"])\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(bow_train_with_bigrams.toarray(), train_y)\n",
        "y_pred = model.predict(bow_test_with_bigrams.toarray())\n",
        "\n",
        "print( \"accuracy \",100 * metrics.accuracy_score(actual_test_set_y,y_pred))\n",
        "print( \"f1_Score \",100 * f1_score(actual_test_set_y,y_pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy  55.70469798657718\n",
            "f1_Score  52.90199809705044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL7fTOm9RLaz"
      },
      "source": [
        "## 4) Laplace Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCEq-BB3E32d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b8b93bb6-28a9-4061-9173-87897afce6cf"
      },
      "source": [
        "model = MultinomialNB(alpha=1.0)\n",
        "model.fit(bow_train.toarray(),train_y)\n",
        "y_pred = model.predict(bow_test.toarray())\n",
        "\n",
        "print( \"accuracy \",100 * metrics.accuracy_score(actual_test_set_y,y_pred))\n",
        "print( \"f1_Score \",100 * f1_score(actual_test_set_y,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy  68.14317673378076\n",
            "f1_Score  63.59918200408998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLihCmuhaRu_"
      },
      "source": [
        "## Conclusion: The best improvement technique was laplace smoothing. Accuracy increased from 51,85 % to 68,14 % and f1_score also increased from 51,48 % to 63.59 %. However, removing stopwords lead to a insigificant reduce of  accuracies. The reason is that in some occasions these techniques can change completely the meaning of the sentence and cause unpredictable results. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KbdJbSNK2Km"
      },
      "source": [
        "# TF-IDF and Part-of-Speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kO67XwvUh5Y"
      },
      "source": [
        "# Updating part of speech array of 4 columns\n",
        "\n",
        "def update_pos_array(pos_array, pos_list, total_words, index): \n",
        "  \n",
        "    # occurances of pos (Adverbs, Verbs, Adjectives, Nouns)\n",
        "    pos_counters = [0,0,0,0]\n",
        "  \n",
        "    for item in pos_list:\n",
        "        if \"RB\" in item[1]: \n",
        "            pos_counters[0] += 1\n",
        "        elif \"VB\" in item[1]:\n",
        "            pos_counters[1] += 1\n",
        "        elif \"JJ\" in item[1]:\n",
        "            pos_counters[2] += 1\n",
        "        elif \"NN\" in item[1]: \n",
        "            pos_counters[3] += 1\n",
        "\n",
        "    # creating list of frequencies \n",
        "    pos_fractions = [x / total_words for x in pos_counters]\n",
        "    # updating array\n",
        "    pos_array[index][:] = pos_fractions \n",
        "  \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV-6v040LkVr"
      },
      "source": [
        "## Creating pos array of test and train set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVhCYdylQ0NV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "119c0e61-32b8-48f5-e31d-6f549a1f2e10"
      },
      "source": [
        "\n",
        "# Columns: fractionAdverbs,fractionVerbs,fractionAdjectives,fractionNouns\n",
        "pos_array_train = np.zeros((train_set.shape[0],4), dtype=float) \n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "index = 0\n",
        "for comment in train_set.Comment:\n",
        "    text = nltk.word_tokenize(comment)\n",
        "    total_words = len(text)\n",
        "    pos_list = nltk.pos_tag(text)\n",
        "    update_pos_array(pos_array_train, pos_list, total_words, index)\n",
        "    index = index + 1\n",
        "\n",
        "pos_array_test = np.zeros((test_set.shape[0],4), dtype=float) \n",
        "\n",
        "index = 0\n",
        "for comment in test_set.Comment:\n",
        "    text = nltk.word_tokenize(comment)\n",
        "    total_words = len(text)\n",
        "    pos_list = nltk.pos_tag(text)\n",
        "    update_pos_array(pos_array_test, pos_list, total_words, index)\n",
        "    index = index + 1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLEK7MLKLunh"
      },
      "source": [
        "## Creating new tfidf-pos array for test and train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acN6qSCs8j6v"
      },
      "source": [
        "from scipy import sparse\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
        "\n",
        "tfidf_train = tfidf_vectorizer.fit_transform(train_set[\"Comment\"])\n",
        "tfidf_train = tfidf_train.toarray()\n",
        "tfidf_train = np.hstack((tfidf_train, pos_array_train))\n",
        "tfidf_train_sparsed = sparse.csr_matrix(tfidf_train)\n",
        "\n",
        "tfidf_test  = tfidf_vectorizer.transform(test_set[\"Comment\"])\n",
        "tfidf_test = tfidf_test.toarray()\n",
        "tfidf_test = np.hstack((tfidf_test, pos_array_test))\n",
        "tfidf_test_sparsed = sparse.csr_matrix(tfidf_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SVMSbF67GeU"
      },
      "source": [
        "## Training new tfidf-pos array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYZM_or07M8i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "a43c9b6f-0802-426e-919f-7b877eed7a0f"
      },
      "source": [
        "# Training data with 2 models using default parameters\n",
        "# We will experiment with parameters later on beating the benchmark with our test data\n",
        "\n",
        "Find_Classification(SVC(),  tfidf_train_sparsed , train_y, \"SVC TF-IDF PoS\")\n",
        "Find_Classification(RandomForestClassifier(),  tfidf_train_sparsed , train_y, \"RandomForrest TF-IDF PoS\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC TF-IDF PoS Accuracy metric 80.63406798175158\n",
            "SVC TF-IDF PoS F1 metric 45.318343608245264\n",
            "\n",
            "\n",
            "RandomForrest TF-IDF PoS Accuracy metric 78.53061749020112\n",
            "RandomForrest TF-IDF PoS F1 metric 34.007941070585\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLESwfqLWkYW"
      },
      "source": [
        "## Evaluating models on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH8wctjvQdZJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "76bf5cce-c933-46b3-c393-b291884e21cb"
      },
      "source": [
        "# SVC\n",
        "\n",
        "model = SVC()\n",
        "model.fit(tfidf_train_sparsed,train_y)\n",
        "y_pred = model.predict(tfidf_test_sparsed)\n",
        "\n",
        "print( \"SVC accuracy \",100 * metrics.accuracy_score(actual_test_set_y,y_pred))\n",
        "print( \"SVC f1_Score\",100 * f1_score(actual_test_set_y,y_pred))\n",
        "\n",
        "# RandomForest\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(tfidf_train_sparsed,train_y)\n",
        "y_pred = model.predict(tfidf_test_sparsed)\n",
        "\n",
        "print( \"\\n\\nRandomForest accuracy \",100 * metrics.accuracy_score(actual_test_set_y,y_pred))\n",
        "print( \"RandomForest f1_Score \",100 * f1_score(actual_test_set_y,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC accuracy  66.9351230425056\n",
            "SVC f1_Score 54.46703635243377\n",
            "\n",
            "\n",
            "RandomForest accuracy  61.61073825503356\n",
            "RandomForest f1_Score  37.73584905660377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXbxk-iuWMW1"
      },
      "source": [
        "## Beating the benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enjwbCmhXP7X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "bd93bd1c-18b0-467d-e269-bad120010169"
      },
      "source": [
        "# SVC\n",
        "\n",
        "model = SVC(kernel='rbf', C = 10,  gamma=0.1)\n",
        "model.fit(tfidf_train_sparsed,train_y)\n",
        "y_pred = model.predict(tfidf_test_sparsed)\n",
        "\n",
        "print( \"SVC accuracy \",100 * metrics.accuracy_score(actual_test_set_y,y_pred))\n",
        "print( \"SVC f1_Score \",100 * f1_score(actual_test_set_y,y_pred))\n",
        "\n",
        "# RandomForrest\n",
        "\n",
        "model = RandomForestClassifier(n_estimators= 100, max_depth= None, max_features = 0.4, random_state= 11)\n",
        "model.fit(tfidf_train_sparsed,train_y)\n",
        "y_pred = model.predict(tfidf_test_sparsed)\n",
        "\n",
        "print( \"\\n\\nRandomForest accuracy \",100 * metrics.accuracy_score(actual_test_set_y,y_pred))\n",
        "print( \"RandomForest f1_Score \",100 * f1_score(actual_test_set_y,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC accuracy  71.81208053691275\n",
            "SVC f1_Score  67.82431052093973\n",
            "\n",
            "\n",
            "RandomForest accuracy  68.7248322147651\n",
            "RandomForest f1_Score  60.125499144324024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUVlQClB1AGV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d44b3169-ed46-407c-bba0-a63b3493ebd5"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "model = SGDClassifier(loss='modified_huber',shuffle=True, random_state=100)\n",
        "model.fit(tfidf_train_sparsed,train_y)\n",
        "y_pred = model.predict(tfidf_test_sparsed)\n",
        "\n",
        "print( \"SGDClassifier accuracy \",100 * metrics.accuracy_score(actual_test_set_y,y_pred))\n",
        "print( \"SGDClassifier f1_Score \",100 * f1_score(actual_test_set_y,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SGDClassifier accuracy  72.25950782997764\n",
            "SGDClassifier f1_Score  67.64091858037577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey1zCNp2tlPr"
      },
      "source": [
        "## Conclusion: With models SVC and RandomForrest, after some tuning on the parameters we managed to increase accuracy from 66.93% to 71.81% and from 62.68% to 67.64% respectively. However, the best score was with another model (SGDClassifier) on accuracy metric around 72.25%.\n"
      ]
    }
  ]
}